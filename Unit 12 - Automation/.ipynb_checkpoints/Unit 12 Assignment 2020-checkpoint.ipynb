{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium\n",
    "---\n",
    "<a class=\"anchor\" id=\"selenium\"></a>\n",
    "\n",
    "Often, you're going to need to go to many different websites to scrape data. The package Selenium automates this process for you. \n",
    "\n",
    "First, we'll need to download it. \n",
    "\n",
    "DO THIS ASSIGNMENT ON YOUR LOCAL COMPUTER NOT COCALC.\n",
    "\n",
    "If you have Anaconda installed already, try typing into your terminal: \n",
    "\n",
    "conda install -c conda-forge selenium\n",
    "\n",
    "OR if that doesn't work:\n",
    "\n",
    "pip install selenium\n",
    "\n",
    "Then download the latest version of chromedriver directly from the link below. Download whichever link works for your version of Chrome. To figure out which version you have: when you're in Chrome, you can click on Chrome - About Google Chrome.\n",
    "\n",
    "https://sites.google.com/a/chromium.org/chromedriver/downloads\n",
    "\n",
    "Unzip the chromedriver file and move it into your Applications folder.\n",
    "\n",
    "\n",
    "Then type into your terminal:\n",
    "\n",
    "pip install webdriver_manager\n",
    "\n",
    "Now try running this cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "driver.get(\"https://images.google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? You should have gotten a browser window that popped up and went to the google images site. \n",
    "<img src=\"images/selenium1.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "Whoa! What if we want to search for Kanye West pics? We'll need to type something into the search text box. To find out how to reference the text box, we'll right click on it and go to Inspect. Then, whatever blue lines get highlighted in the right pane, right click on that, and select Copy - Copy XPath. \n",
    "\n",
    "\n",
    "<img src=\"images/selenium2.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "When I searched, I got \"//*[@id=\"sbtc\"]/div/div[2]/input\", which you see below, but yours will definitely be different. Replace what I have with what you have. \n",
    "\n",
    "Only the outermost quotation marks should be single quotation marks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"4b5c08409dfccc18f63b34cb3e6cd3c8\", element=\"0d5ecb88-8d18-4758-acf6-7cc840964eaf\")>\n"
     ]
    }
   ],
   "source": [
    "search_box = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/div/div[2]/input')\n",
    "print(search_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it found it. Now let's tell Chromium to type \"Kanye West\" into the search box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box.send_keys(\"Kanye West\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you see what just happened on your google webpage? Now, let's press enter to complete our search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to download the first image that comes up? Right click on it and press inspect. \n",
    "\n",
    "<img src=\"images/selenium3.jpg\" style=\"width: 200px;\"/>\n",
    "\n",
    "Then right click again on the blue highlighted html text that comes up and choose Copy - XPath. \n",
    "\n",
    "<img src=\"images/selenium4.jpg\" style=\"width: 200px;\"/>\n",
    "\n",
    "That Xpath is now copied.\n",
    "\n",
    "Now copy that XPath between the SINGLE quotation marks below. Mine is '//*[@id=\"islrg\"]/div[1]/div[1]/a[1]/div[1]/img' but yours will almost certainly be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]/div[1]/a[1]/div[1]/img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's click on this pic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are on a new page. If we wanted to know the url of the page we are currently on, we could type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/search?tbm=isch&source=hp&biw=1200&bih=657&ei=4UK8XpH6FZfv-gT18qCwDQ&q=Kanye+West&oq=Kanye+West&gs_lcp=CgNpbWcQAzICCAAyAggAMgIIADICCAAyAggAMgIIADICCAAyAggAMgIIADICCABQoOMDWJTkA2Cd9gNoAHAAeACAAZQBiAGfA5IBAzIuMpgBAKABAaoBC2d3cy13aXotaW1nsAEA&sclient=img&ved=0ahUKEwjR7oycwrHpAhWXt54KHXU5CNYQ4dUDCAc&uact=5#imgrc=nbWxwEpN37u4gM'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.current_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. Let's use XPath again, which is typically the easiest way to search for something on a webpage. To do this, right click on the larger Kanye image, choose inspect, and see the blue text that got highlighted. Now, right click on the blue text and choose \"Copy - XPath\". It should look like this:\n",
    "\n",
    "<img src=\"images/xpath.jpg\" style=\"width: 200px;\"/>\n",
    "\n",
    "Now, we can paste what we just copied into this new search. Mine is //*[@id=\"Sva75c\"]/div/div/div[3]/div[2]/c-wiz/div[1]/div[1]/div/div[2]/a/img but yours will almost certainly be different so change it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"4b5c08409dfccc18f63b34cb3e6cd3c8\", element=\"50cce5b0-3117-4cb8-8a39-37ae43bc00dc\")>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic = search.find_element_by_xpath('//*[@id=\"Sva75c\"]/div/div/div[3]/div[2]/c-wiz/div[1]/div[1]/div/div[2]/a/img')\n",
    "pic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there was text stored here that we could scrape off, we could type the following. (In this case, there isn't, but you'll use this next command to do Exercise 1 below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(pic.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What pieces of info might this pic include? To find out, right click-Inspect the Kanye picture again and investigate the text that comes up in blue. It should include something like \"src=...\" and \"class = ....\". \n",
    "\n",
    "<img src=\"images/selenium5.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "Selenium allows us to grab all of this info. We can obtain the class using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n3VNCb\n"
     ]
    }
   ],
   "source": [
    "myclass = pic.get_attribute('class')\n",
    "print(myclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the url, we could type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.biography.com/.image/t_share/MTU0OTkwNDUxOTQ5MDUzNDQ3/kanye-west-attends-the-christian-dior-show-as-part-of-the-paris-fashion-week-womenswear-fall-winter-2015-2016-on-march-6-2015-in-paris-france-photo-by-dominique-charriau-wireimage-square.jpg\n"
     ]
    }
   ],
   "source": [
    "url = pic.get_attribute('src')\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we download this picture? We can use requests to communicate with this url and write its contents to a file called kanye.jpg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(url)\n",
    "with open('kanye.jpg', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you now have a saved image of Kanye in the same folder that this Jupyter Notebook is in!!! Whoaaa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we close the web browser window? Type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Selenium 1\n",
    "\n",
    "Use Selenium to go to http://www.boxofficemojo.com/movies/?id=matrix.htm and use Selenium to print the Domestic Total Gross.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Selenium 2\n",
    "\n",
    "Use Selenium to go to http://www.imdb.com/ and to type into the search box Kanye West. You won't quite be there yet because two names are listed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Selenium\n",
    "Once you are on Kanye's page, find the src of his face and/or the id of his face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Selenium\n",
    "While still on Kanye's page, find the XPath location of the Kanye pic and use Selenium to find the url of the pic and download it as \"kanye2.jpg\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium and BeautifulSoup\n",
    "\n",
    "Here's another example. Let's use Selenium to get the temperature for all the zip codes in Portland. First go to http://zipcode.org/city/OR/PORTLAND and scroll down to see the list of zip codes.\n",
    "\n",
    "Let's first use BeautifulSoup to get the zip codes. If we right click - inspect the zip codes, we see that the zip codes are listed under class = Link_List_Text. \n",
    "\n",
    "<img src=\"images/zip1.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "We can use Beautiful Soup to find them and save them all to a list. Since there are multiple zip codes we'll use find_all instead of find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['97201', '97202', '97203', '97204', '97205', '97206', '97207', '97208', '97209', '97210', '97211', '97212', '97213', '97214', '97220', '97221', '97215', '97216', '97217', '97218', '97219', '97222', '97223', '97227', '97228', '97229', '97231', '97232', '97233', '97236', '97256', '97258', '97266', '97268', '97269', '97280', '97290', '97291', '97292', '97293', '97224', '97225', '97230', '97238', '97239', '97240', '97242', '97267', '97281', '97282', '97283', '97286', '97294', '97296', '97298']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://zipcode.org/city/OR/PORTLAND'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "zip_codes = []\n",
    "data = soup.find_all(class_='List_Link_Text')\n",
    "for link in data:\n",
    "    text = link.get_text()\n",
    "    if 'Zip' in text:\n",
    "        zip_codes.append(' '.join(text.split()[0:1]))\n",
    "        \n",
    "print(zip_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use Selenium to search the temperature for the zip code 97201.\n",
    "\n",
    "First go to www.weather.gov\n",
    "\n",
    "Let's use right click - inspect - XPath to find the search box location and copy it into the code below:\n",
    "\n",
    "<img src=\"images/zip2.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "Replace your path with the one I have below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "url = \"https://www.weather.gov/\"\n",
    "\n",
    "driver.get(url)\n",
    "search = driver.find_element_by_xpath('//*[@id=\"inputstring\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note carefully what you have to do on https://forecast.weather.gov/ to access the weather. You need to click into the text box, type the zip code, press the tab button, and press enter. Let's do that using Selenium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.click()\n",
    "search.send_keys(\"97201\")\n",
    "search.send_keys(\"\\t\")\n",
    "search.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we see it didn't work because the website was a little less responsive than our program. Let's close that window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try again, let's add in a one second delay before pressing return to give the website time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "url = \"https://www.weather.gov/\"\n",
    "\n",
    "driver.get(url)\n",
    "search = driver.find_element_by_xpath('//*[@id=\"inputstring\"]')\n",
    "\n",
    "search.click()\n",
    "search.send_keys(\"97201\")\n",
    "search.send_keys(\"\\t\")\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "search.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're in the correct spot, we use Selenium to find the temperature by typing right click - inspect - right click - copy XPath. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"current_conditions-summary\"]/p[2]').text\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can iterate through the first 10 zip codes of the zip codes we found on the first website to find the temperatures at each and store them to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97201 59°F\n",
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97202 59°F\n",
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97203 57°F\n",
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97204 59°F\n",
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97205 59°F\n",
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97206 59°F\n",
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97207 59°F\n",
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97208 59°F\n",
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97209 59°F\n",
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "97210 59°F\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "temps = []\n",
    "\n",
    "for i in range(3): # let's just do first 3 for time\n",
    "\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    url = \"https://www.weather.gov/\"\n",
    "\n",
    "    driver.get(url)\n",
    "    search = driver.find_element_by_xpath('//*[@id=\"inputstring\"]')\n",
    "\n",
    "    search.click()\n",
    "    search.send_keys(zip_codes[i])\n",
    "    search.send_keys(\"\\t\")\n",
    "    time.sleep(1)\n",
    "    search.send_keys(Keys.RETURN)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    temp = driver.find_element_by_xpath('//*[@id=\"current_conditions-summary\"]/p[2]').text\n",
    "    print(zip_codes[i], temp)\n",
    "    temps.append(temp)\n",
    "    \n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing to note is that while XPath is almost always the best way to search for something, you may need to search by id sometimes. Note when we inspect the weather.gov website, we see that the id is \"inputstring\":\n",
    "\n",
    "<img src=\"images/selenium6.jpg\" style=\"width: 600px;\"/>\n",
    "\n",
    "Therefore, we can use find_element_by_id with that id tag inside to also locate the text box and insert our zip code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "url = \"https://www.weather.gov/\"\n",
    "\n",
    "driver.get(url)\n",
    "search = driver.find_element_by_id('inputstring')\n",
    "\n",
    "search.click()\n",
    "search.send_keys(\"97201\")\n",
    "search.send_keys(\"\\t\")\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "search.send_keys(Keys.RETURN)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one more example, note that there is a PLURAL form driver.find_elements_by_xpath if there is more than one element that you want to find on the page. For example, suppose that I wanted to print all the weaknesses for Squirtle located here:\n",
    "\n",
    "https://www.pokemon.com/us/pokedex/squirtle\n",
    "\n",
    "Right click-inspect the first weakness. \n",
    "\n",
    "Notice that it contains:\n",
    "\n",
    "href=\"/us/pokedex/?weakness\"\n",
    "\n",
    "All of the weaknesses contain this general form \"href=\"/us/pokedex/?weakness...\"\n",
    "\n",
    "To generalize our search to all hrefs that contain this first part, we can use the \"contains\" command and then iterate through all of the hits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for [chromedriver 81.0.4044.138 mac64] driver in cache \n",
      "File found in cache by path [/Users/shareshianl/.wdm/drivers/chromedriver/81.0.4044.138/mac64/chromedriver]\n",
      "Grass\n",
      "Electric\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "url = \"https://www.pokemon.com/us/pokedex/squirtle\"\n",
    "driver.get(url)\n",
    "selector = '//a[contains(@href, \"/us/pokedex/?weakness\")]'\n",
    "for anchor in driver.find_elements_by_xpath(selector):\n",
    "    print(anchor.text)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - More Selenium 1\n",
    "Create a loop that prints the weaknesses for Squirtle, Bulbasaur, and Charmander."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - More Selenium 2\n",
    "Create a loop that prints the types for Squirtle, Bulbasaur, and Charmander."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
