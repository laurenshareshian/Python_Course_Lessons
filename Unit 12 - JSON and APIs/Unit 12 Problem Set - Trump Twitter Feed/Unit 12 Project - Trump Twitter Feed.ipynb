{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you will use your knowledge of datetime and matplotlib to plot the number of Donald's tweets versus the a.) date, b.) day of the week and c.) time of the day. Also, you will analyze his most used words. \n",
    "\n",
    "1.First, to get his tweets, we'll actually need to make a loop and hit the twitter API multiple times (since he's got a lotttt of tweets and Twitter has a limit to the amount of tweets that you can request at once.) This next code will get all of these tweets and save them to a file called new_tweets.json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newest_tweet Today, my Administration is launching the most sweeping action in history to lower the price of prescription drugs… https://t.co/YHscW623cr Fri May 11 19:30:16 +0000 2018\n",
      "oldest_tweet Ungrateful TRAITOR Chelsea Manning, who should never have been released from prison, is now calling President Obama a weak leader. Terrible! Thu Jan 26 11:04:24 +0000 2017\n"
     ]
    }
   ],
   "source": [
    "import twurl2\n",
    "import json\n",
    "import hidden\n",
    "\n",
    "outfile = open('new_tweets.json', 'w')\n",
    "wrap_list=[] #since I need to make a twitter API call repeatedly I will wrap the JSON info into a list\n",
    "\n",
    "TWITTER_URL = 'https://api.twitter.com/1.1/statuses/user_timeline.json'\n",
    "acct = 'realdonaldtrump'\n",
    "twittercount=200 #pull 200 tweets at a time (the max)\n",
    "secrets = hidden.oauth()\n",
    "full_url=''.join([TWITTER_URL,'?','count=',str(twittercount),'&', 'screen_name=', acct])\n",
    "user_timeline = twurl2.oauth_req( full_url, secrets['token_key'], secrets['token_secret'], \"GET\" )\n",
    "js=json.loads(user_timeline)\n",
    "wrap_list.append(js)\n",
    "\n",
    "#twitter gives an ID with each tweet...keep hitting the twitter API until you run out of new IDs\n",
    "old_max_id=0\n",
    "max_id=js[len(js) - 1]['id']\n",
    "\n",
    "while old_max_id!=max_id:\n",
    "    old_max_id=max_id\n",
    "    full_url=''.join([TWITTER_URL,'?','count=',str(twittercount),'&', 'screen_name=', acct, '&', 'max_id=', str(max_id)])\n",
    "    user_timeline = twurl2.oauth_req( full_url, secrets['token_key'], secrets['token_secret'], \"GET\" )\n",
    "    js = json.loads(user_timeline)\n",
    "\n",
    "    max_id=js[len(js) - 1]['id']\n",
    "    wrap_list.append(js)\n",
    "\n",
    "json.dump(wrap_list, outfile)\n",
    "outfile.close()\n",
    "\n",
    "print('newest_tweet', wrap_list[0][0]['text'],wrap_list[0][0]['created_at'])\n",
    "print('')\n",
    "print('oldest_tweet', wrap_list[-1][0]['text'],wrap_list[-1][0]['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Actually, Donald has older tweets than this. The Twitter API just doesn't let us access them. Luckily, Lauren has been saving his tweets for the last several years so we can merge the newer tweets that you just scraped with the older ones that she did in order to have a more complete data set. In the following code, we'll merge your list with hers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique tweets 6167\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "js=[]\n",
    "\n",
    "#load older tweets\n",
    "with open('old_tweets.json') as json_data1:\n",
    "    js1 = json.load(json_data1)\n",
    "\n",
    "#load newer tweets\n",
    "with open('new_tweets.json') as json_data2:\n",
    "    js2 = json.load(json_data2)\n",
    "\n",
    "#merge both tweets\n",
    "for j in range(len(js1)):\n",
    "    js.append(js1[j])\n",
    "\n",
    "for j in range(len(js2)):\n",
    "    for i in range(len(js2[j])):\n",
    "        js.append(js2[j][i])\n",
    "\n",
    "#delete duplicates based on creation time\n",
    "datelist=[]\n",
    "count=0\n",
    "dups_removed=[]\n",
    "\n",
    "for j in range(len(js)):\n",
    "    date=js[j]['created_at']\n",
    "    if date not in datelist: #remove duplicates\n",
    "        datelist.append(date)\n",
    "        count = count + 1\n",
    "        dups_removed.append(js[j])\n",
    "\n",
    "#update donalddata.json to include all non-duplicate tweets\n",
    "outfile = open('donalddata.json', 'w')\n",
    "json.dump(dups_removed, outfile)\n",
    "outfile.close()\n",
    "\n",
    "print('number of unique tweets', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Load the donalddata.json data that you have just created back in in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Create three lists for the tweet texts, created_at, and number_of_retweets data. Then store them in a single pandas dataframe called df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Which did the tweet that had the most retweets say? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Let's convert the Twitter data (in UTC time) to Eastern Time Zone time. Here we create a new column called eastern_time_zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>eastern_time_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thu Mar 23 01:04:32 +0000 2017</td>\n",
       "      <td>2896</td>\n",
       "      <td>RT @mitchellvii: Trump always ends up being ri...</td>\n",
       "      <td>2017-03-22 21:04:32-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thu Mar 23 01:03:18 +0000 2017</td>\n",
       "      <td>1625</td>\n",
       "      <td>RT @mitchellvii: EXACTLY AS I SAID - House Int...</td>\n",
       "      <td>2017-03-22 21:03:18-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Mar 22 13:09:35 +0000 2017</td>\n",
       "      <td>10233</td>\n",
       "      <td>Big day for healthcare. Working hard!</td>\n",
       "      <td>2017-03-22 09:09:35-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue Mar 21 18:12:05 +0000 2017</td>\n",
       "      <td>13207</td>\n",
       "      <td>Today on #NationalAgDay, we honor our great Am...</td>\n",
       "      <td>2017-03-21 14:12:05-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Mar 21 17:33:23 +0000 2017</td>\n",
       "      <td>13448</td>\n",
       "      <td>Honored to sign S.442 today. With this legisla...</td>\n",
       "      <td>2017-03-21 13:33:23-04:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  retweet_count  \\\n",
       "0  Thu Mar 23 01:04:32 +0000 2017           2896   \n",
       "1  Thu Mar 23 01:03:18 +0000 2017           1625   \n",
       "2  Wed Mar 22 13:09:35 +0000 2017          10233   \n",
       "3  Tue Mar 21 18:12:05 +0000 2017          13207   \n",
       "4  Tue Mar 21 17:33:23 +0000 2017          13448   \n",
       "\n",
       "                                                text         eastern_time_zone  \n",
       "0  RT @mitchellvii: Trump always ends up being ri... 2017-03-22 21:04:32-04:00  \n",
       "1  RT @mitchellvii: EXACTLY AS I SAID - House Int... 2017-03-22 21:03:18-04:00  \n",
       "2              Big day for healthcare. Working hard! 2017-03-22 09:09:35-04:00  \n",
       "3  Today on #NationalAgDay, we honor our great Am... 2017-03-21 14:12:05-04:00  \n",
       "4  Honored to sign S.442 today. With this legisla... 2017-03-21 13:33:23-04:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "from dateutil.parser import parse\n",
    "\n",
    "tz = pytz.timezone('US/Eastern')\n",
    "\n",
    "time_zone = []\n",
    "for j in range(len(js)):\n",
    "    time_zone.append(parse(js[j]['created_at']).astimezone(tz))\n",
    "    \n",
    "df['eastern_time_zone'] = time_zone\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Create a new column that includes just the hour of each tweets (use pandas built in datetime capabilities to do this in one line). Then plot a histogram of the date versus the number of tweets on that date. \n",
    "\n",
    "1. Label your axes.\n",
    "\n",
    "2. Use bins = np.range(-.5,24.5,1) to center each bin at the hour and rwidth=0.9 to provide some separation.\n",
    "\n",
    "3. Google how to add x-axis tick labels at each hour mark \"0,1,2,3...23\"\n",
    "\n",
    "Make sure the bins and the labels are centered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.From the graph above, which hour does he tweet at most often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.How many tweets has he sent between midnight and 4:00 am in this dataset? You can do this in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Make a histogram of day of week vs number of tweets using pandas built in datetime capabilities. Recall that Monday corresponds to 0. \n",
    "\n",
    "Change the x-axis labels so that you see \"Mon, Tues, etc.\" instead of \"0,1,2....\" You will probably need to google this.\n",
    "\n",
    "Make sure the bins and the labels are centered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.Next, we'll want to make a bar chart for date versus number of tweets. This will take a couple of steps. First, create a dictionary called count_days such that the key is the date (just the month-day-year - not the hour or other stuff - you can do this easily) and the value is the number of tweets on that date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.Next, plot this dictionary using a histogram. Hint: google \"python plot dictionary histogram\" in order to do this. \n",
    "\n",
    "Put the line \"plt.rcParams['figure.figsize'] = [10, 5]\" BEFORE you plot the histogram in order to see the dates along the x-axis clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.On which date did he tweet the most? Hint: you can create a sorted list of tuples if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.What were the texts of those tweets on that date? Hint: you can do this in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.Now we'll explore Trump's most frequently used words. To do this, create a loop that iterates through each tweet text and saves them all to one long string called \"all_tweets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.Make the entire string lower case (since we want Hillary and hillary to be equivalent) and resave it as \"cleaned_tweets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.Also, we'll want to strip all of the punctuation. Do do that, we can use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "cleaned_tweets = cleaned_tweets.translate(str.maketrans('','',string.punctuation))\n",
    "cleaned_tweets[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.Create a dictionary called counts whose key is each word and whose value is the number of times that that word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.Create a sorted list of tuples called tuple_list in reverse order of his most frequently used words. Only print the words that occur at least ten times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.One last thing...word cloud visualizations are kind of a hot thing right now. Let's make one, but get rid of the boring words like \"the\" that aren't very interesting. Recreate the count dictionary in number 18 above but add keys that are not in the boring list below:\n",
    "\n",
    "boring_words=['at', 'be','was', 'by', 'our','do','so','amp','by','it','its','at','by' 'from', 'as', 'but','am','of', 'a', 'you', 'on', 'the', 'is', 'to', 'and', 'in', 'has', 'are', 'not', 'an', 'in', 'or', 'for', 'who', 'that', 'have', 'there', 'just', 'their', 'were', 'what' , 'with', 'will', 'than', 'about', 'this','if','from','would','been','had']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21.We'll save the words and their frequencies to a javascript file that we can view on a webpage. Here's the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to donaldwords.js\n"
     ]
    }
   ],
   "source": [
    "# ##########################################\n",
    "#plot counts using d3, to view the visualization open the twitterword.htm file in a web browser\n",
    "# ##########################################\n",
    "x = sorted(counts, key=counts.get, reverse=True)\n",
    "highest = None\n",
    "lowest = None\n",
    "for k in x[:100]:\n",
    "    if highest is None or highest < counts[k] :\n",
    "        highest = counts[k]\n",
    "    if lowest is None or lowest > counts[k] :\n",
    "        lowest = counts[k]\n",
    "\n",
    "# Spread the font sizes across 20-100 based on the count\n",
    "bigsize = 80\n",
    "smallsize = 20\n",
    "\n",
    "fhand = open('donaldwords.js','w')\n",
    "fhand.write(\"donaldwords = [\")\n",
    "first = True\n",
    "for k in x[:100]:\n",
    "    if not first : fhand.write( \",\\n\")\n",
    "    first = False\n",
    "    size = counts[k]\n",
    "    size = (size - lowest) / float(highest - lowest)\n",
    "    size = int((size * bigsize) + smallsize)\n",
    "    fhand.write(\"{text: '\"+k+\"', size: \"+str(size)+\"}\")\n",
    "fhand.write( \"\\n];\\n\")\n",
    "\n",
    "print (\"Output written to donaldwords.js\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22.Now open the twitterword.html file in a web browser to view the word cloud. Take a screenshot of it and save it as twitter.jpg. Then run the code to see the screenshot below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "double click into this cell and then run it\n",
    "<img src=\"twitter.jpg\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23.The word cloud was created using the D3 JavaScript library for visualizing data. It is super hot right now! You could pretty much get hired right now if you are good with it. Check out some other visualizations you can do with it here:\n",
    "\n",
    "https://github.com/d3/d3/wiki/Gallery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot\n",
    "24.Now let's make a Donald Trump chatbot that uses his previous tweets to create new tweets. We'll go back to the string all_tweets that contains all of his tweets before punctuation is removed.\n",
    "\n",
    "First, we'll remove certain punctuation (and hashtags and hyperlinks) and put spaces between other punctuation. We can do that most easily using regular expressions. The regular expression package is very powerful - there are loads of online tutorials for using regular expressions to manipulate strings. I highly recommend reading about them. But in the meantime, you can just read my code carefully below and run the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "all_tweets = re.sub(r\"http\\S+\", \"\", all_tweets) #remove hyperlinks\n",
    "all_tweets = re.sub(r\"amp\\S+\", \"\", all_tweets) #remove ampersand symbol\n",
    "all_tweets = re.sub(r\"\\t\", \"\", all_tweets)  # remove tabs\n",
    "all_tweets = re.sub(r\"\\v\", \"\", all_tweets)  # remove vertical space\n",
    "all_tweets = re.sub(r\"\\r\", \"\", all_tweets)  # remove carriage return\n",
    "all_tweets = re.sub(r\"\\n\", \"\", all_tweets)  # remove new lines\n",
    "all_tweets = re.sub(r\"\\(\", \"\", all_tweets)  # remove parenthesis\n",
    "all_tweets = re.sub(r\"\\)\", \"\", all_tweets)  # remove parenthesis\n",
    "all_tweets = re.sub(r\"\\.\\.\\.\", \"\", all_tweets)  # remove ...\n",
    "all_tweets = re.sub(r\"\\. \\. \\. \", \"\", all_tweets)  # remove . . .\n",
    "all_tweets = re.sub(r\"\\\"\", \"\", all_tweets)  # remove quotations\n",
    "all_tweets = re.sub(r\"!\", \"! \", all_tweets)  # insert space after !\n",
    "all_tweets = re.sub(r\"\\.\", \". \", all_tweets)  # insert space after .\n",
    "all_tweets = re.sub(r\"\\?\", \"? \", all_tweets)  # insert space after ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25.Split the string all_tweets into a list of words called words. Remove words that contain just punctuation in the following list:\n",
    "\n",
    "bad_words=['…', '.', '!', '?', ',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26.Okay, now gets to the fun part where we actually get to make a chatbot. We'll do this using Markov chains. A Markov chain is a randomly determined model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. What does this mean?\n",
    "\n",
    "We'll make a key-value dictionary where each key is a two word phrase and each value is a list containing all the possible single words that come after that phrase. Here's a concrete example. Read it carefully, paying special attention to the \"and i\" phrase.\n",
    "\n",
    "\"hi my name is Al and i live in a box that i like very much and i can live in there as long as i want\"\n",
    "\n",
    "\"hi my\" -> [\"name\"]\n",
    "\n",
    "\"my name\" -> [\"is\"]\n",
    "\n",
    "\"name is\" -> [\"Al\"]\n",
    "\n",
    "\"is Al\" -> [\"and\"]\n",
    "\n",
    "\"Al and\" -> [\"i\"]\n",
    "\n",
    "\"and i\" -> [\"live\"]\n",
    "\n",
    "........\n",
    "\n",
    "\"and i\" -> [\"live\", \"can\"]\n",
    "\n",
    "........\n",
    "\n",
    "\"i can\" -> [\"live\"]\n",
    "\n",
    "......\n",
    "\n",
    "Make a dictionary that does this type of Markov chain for all_tweets called word_dict below. Here are a few helpful hints:\n",
    "\n",
    "You can't iterate ALL the way until the end of the list (or else you'll go out of index). You may need to stop a few words short.\n",
    "\n",
    "For each new two word phrase, store the first word value to a LIST. Then, if that two word phrase comes around again, you can append the next possible word to that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27.Now randomly choose a key (two word phrase) to start with and then take that key and print a random value of that key (single word that follows). To do this, go back to Unit 4 to remember how to use random.choice and random.randint.\n",
    "\n",
    "Create a string called new_tweet that contains the random initial starting phrase (called starting_phrase) and the following word, with a space in between.\n",
    "\n",
    "Capitalize the starting word (hint: use .capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28.Update the starting_phrase to now be the last two words of the string, with a space in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29.While the new tweet is less than 140 characters, create a loop that continues to add new words to the new_tweet string by generating a new random number and a new word that follows the last starting_phrase. Each time through the loop, update the starting phrase.\n",
    "\n",
    "Note: You will need to use a try/except because not all pairs of words that you put together are in the word_dict. If you get to a pair that isn't in the word dict, proceed as follows:\n",
    "\n",
    "\n",
    "a.If the pair ends in a period, simply end the sentence.\n",
    "\n",
    "b. If the pair does not end in a period, generate a new random starting phrase and continue creating a new sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30.Run the last several lines of code several times. Copy and paste the new_tweet that sounds most realistic below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional - Make a chatbot of another celebrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert optional"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
