{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    "---\n",
    "- [File Input](#input)\n",
    "- [Delimiters](#delimiters)\n",
    "- [CSV files](#csv)\n",
    "- [File Output](#output)\n",
    "- [Files in other locations](#locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Input\n",
    "---\n",
    "<a class=\"anchor\" id=\"input\"></a>\n",
    "So far, we have just taken in short words and sentences from the user. However, in reality we will want to examine much larger sets of text, including word documents, spreadsheets, and web pages.  In order to do this, we need to learn how to tell Python to look through a file.\n",
    "\n",
    "If your Python program is in the same folder that the text file that you would like to read is in, then we just need the open command. Suppose we want to read the lyrics in a file saved as \"kanye.txt\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try the following code, we will get an error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_io.TextIOWrapper' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c5b2602d4c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kanye.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '_io.TextIOWrapper' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "f = open('kanye.txt')\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we'll need to use the .read command. Remember to always put your file name in quotations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "Man, I promise, she's so self conscious\n",
      "She has no idea what she's doing in college\n",
      "That major that she majored in don't make no money\n",
      "But she won't drop out, her parents will look at her funny\n",
      "\n",
      "\n",
      "Now, tell me that ain't insecure\n",
      "The concept of school seems so secure\n",
      "Sophomore, three years, ain't picked a career\n",
      "She like, screw it, I'll just stay down here and do hair\n",
      "\n",
      "\n",
      "'Cause that's enough money to buy her a few pairs of new airs\n",
      "'Cause her baby daddy don't really care\n",
      "She's so precious with the peer pressure\n",
      "Couldn't afford a car so she named her daughter Alexus\n",
      "\n",
      "\n",
      "She had hair so long that it looked like weave\n",
      "Then she cut it all off now she look like Eve\n",
      "And she be dealing with some issues that you can't believe\n",
      "Single black female, addicted to retail and well\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you oh, it all falls down\n",
      "\n",
      "\n",
      "Man I promise, I'm so self conscious\n",
      "That's why you always see me with at least one of my watches\n",
      "Rollies and Pasha's done drove me crazy\n",
      "I can't even pronounce nothing, pass that Versace\n",
      "\n",
      "\n",
      "Then I spent 400 bucks on this\n",
      "Just to be like you ain't up on this\n",
      "And I can't even go to the grocery store\n",
      "Without some ones that's clean and a shirt with a team\n",
      "\n",
      "\n",
      "It seems we living the American dream\n",
      "The people highest up got the lowest self esteem\n",
      "The prettiest people do the ugliest things\n",
      "For the road to riches and diamond rings\n",
      "\n",
      "\n",
      "We shine because they hate us, floss 'cause they degrade us\n",
      "We trying to buy back our 40 acres\n",
      "And for that paper, look how low we a'stoop\n",
      "Even if you in a Benz, you still a brotha in a coop\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "I say f the police, that's how I treat 'em\n",
      "We buy our way out of jail, but we can't buy freedom\n",
      "We'a buy a lot of clothes but we don't really need 'em\n",
      "Things we buy to cover up what's inside\n",
      "\n",
      "\n",
      "'Cause they made us hate ourself and love they wealth\n",
      "That's why shorty's hollering, \"Where the ballas' at?\"\n",
      "Drug dealer buy Jordans, crackhead buy crack\n",
      "And a white man get paid off of all a dat\n",
      "\n",
      "\n",
      "But I ain't even gon' act holier than thou\n",
      "'Cause f it, I went to Jacob with 25 thou\n",
      "Before I had a house and I'd do it again\n",
      "'Cause I wanna be on 106 and Park pushing a Benz\n",
      "\n",
      "\n",
      "I wanna act ballerific like it's all terrific\n",
      "I got a couple past due bills, I won't get specific\n",
      "I got a problem with spending before I get it\n",
      "We all self conscious, I'm just the first to admit it\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "\n",
      "(I's can't keep workin' like this\n",
      "This grave shift is like a slave ship)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('kanye.txt').read()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to read the first 10 lines of the song, we might try typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when i\n"
     ]
    }
   ],
   "source": [
    "f = open('kanye.txt').read()\n",
    "print(f[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh, oh, this gives us the first 10 characters, not the first 10 lines. Read is a useful function for manipulating files in cases when you want to process the entire contents of a file, but it isn't very good when dealing with large files. To read all of the lines at once, we can use the readlines command, and then print out the first ten lines in a list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oh, when it all, it all falls down\\n', \"I'm telling you, oh, it all falls down\\n\", '\\n', '\\n', 'Oh, when it all, it all falls down\\n', \"I'm telling you, oh, it all falls down\\n\", '\\n', '\\n', \"Man, I promise, she's so self conscious\\n\", \"She has no idea what she's doing in college\\n\"]\n"
     ]
    }
   ],
   "source": [
    "f = open('kanye.txt').readlines()\n",
    "print(f[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, for very large files, it's really not ideal to read the whole file all at once. Rather, we can read one line at a time using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Man, I promise, she's so self conscious\n",
      "\n",
      "She has no idea what she's doing in college\n",
      "\n",
      "That major that she majored in don't make no money\n",
      "\n",
      "But she won't drop out, her parents will look at her funny\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now, tell me that ain't insecure\n",
      "\n",
      "The concept of school seems so secure\n",
      "\n",
      "Sophomore, three years, ain't picked a career\n",
      "\n",
      "She like, screw it, I'll just stay down here and do hair\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'Cause that's enough money to buy her a few pairs of new airs\n",
      "\n",
      "'Cause her baby daddy don't really care\n",
      "\n",
      "She's so precious with the peer pressure\n",
      "\n",
      "Couldn't afford a car so she named her daughter Alexus\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "She had hair so long that it looked like weave\n",
      "\n",
      "Then she cut it all off now she look like Eve\n",
      "\n",
      "And she be dealing with some issues that you can't believe\n",
      "\n",
      "Single black female, addicted to retail and well\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you oh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Man I promise, I'm so self conscious\n",
      "\n",
      "That's why you always see me with at least one of my watches\n",
      "\n",
      "Rollies and Pasha's done drove me crazy\n",
      "\n",
      "I can't even pronounce nothing, pass that Versace\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Then I spent 400 bucks on this\n",
      "\n",
      "Just to be like you ain't up on this\n",
      "\n",
      "And I can't even go to the grocery store\n",
      "\n",
      "Without some ones that's clean and a shirt with a team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "It seems we living the American dream\n",
      "\n",
      "The people highest up got the lowest self esteem\n",
      "\n",
      "The prettiest people do the ugliest things\n",
      "\n",
      "For the road to riches and diamond rings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We shine because they hate us, floss 'cause they degrade us\n",
      "\n",
      "We trying to buy back our 40 acres\n",
      "\n",
      "And for that paper, look how low we a'stoop\n",
      "\n",
      "Even if you in a Benz, you still a brotha in a coop\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I say f the police, that's how I treat 'em\n",
      "\n",
      "We buy our way out of jail, but we can't buy freedom\n",
      "\n",
      "We'a buy a lot of clothes but we don't really need 'em\n",
      "\n",
      "Things we buy to cover up what's inside\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'Cause they made us hate ourself and love they wealth\n",
      "\n",
      "That's why shorty's hollering, \"Where the ballas' at?\"\n",
      "\n",
      "Drug dealer buy Jordans, crackhead buy crack\n",
      "\n",
      "And a white man get paid off of all a dat\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "But I ain't even gon' act holier than thou\n",
      "\n",
      "'Cause f it, I went to Jacob with 25 thou\n",
      "\n",
      "Before I had a house and I'd do it again\n",
      "\n",
      "'Cause I wanna be on 106 and Park pushing a Benz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I wanna act ballerific like it's all terrific\n",
      "\n",
      "I got a couple past due bills, I won't get specific\n",
      "\n",
      "I got a problem with spending before I get it\n",
      "\n",
      "We all self conscious, I'm just the first to admit it\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(I's can't keep workin' like this\n",
      "\n",
      "This grave shift is like a slave ship)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('kanye.txt'):   \n",
    "   print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of extra spaces between the lyrics. We can use the strip command to delete them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "Man, I promise, she's so self conscious\n",
      "She has no idea what she's doing in college\n",
      "That major that she majored in don't make no money\n",
      "But she won't drop out, her parents will look at her funny\n",
      "\n",
      "\n",
      "Now, tell me that ain't insecure\n",
      "The concept of school seems so secure\n",
      "Sophomore, three years, ain't picked a career\n",
      "She like, screw it, I'll just stay down here and do hair\n",
      "\n",
      "\n",
      "'Cause that's enough money to buy her a few pairs of new airs\n",
      "'Cause her baby daddy don't really care\n",
      "She's so precious with the peer pressure\n",
      "Couldn't afford a car so she named her daughter Alexus\n",
      "\n",
      "\n",
      "She had hair so long that it looked like weave\n",
      "Then she cut it all off now she look like Eve\n",
      "And she be dealing with some issues that you can't believe\n",
      "Single black female, addicted to retail and well\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you oh, it all falls down\n",
      "\n",
      "\n",
      "Man I promise, I'm so self conscious\n",
      "That's why you always see me with at least one of my watches\n",
      "Rollies and Pasha's done drove me crazy\n",
      "I can't even pronounce nothing, pass that Versace\n",
      "\n",
      "\n",
      "Then I spent 400 bucks on this\n",
      "Just to be like you ain't up on this\n",
      "And I can't even go to the grocery store\n",
      "Without some ones that's clean and a shirt with a team\n",
      "\n",
      "\n",
      "It seems we living the American dream\n",
      "The people highest up got the lowest self esteem\n",
      "The prettiest people do the ugliest things\n",
      "For the road to riches and diamond rings\n",
      "\n",
      "\n",
      "We shine because they hate us, floss 'cause they degrade us\n",
      "We trying to buy back our 40 acres\n",
      "And for that paper, look how low we a'stoop\n",
      "Even if you in a Benz, you still a brotha in a coop\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, oh, it all falls down\n",
      "\n",
      "\n",
      "I say f the police, that's how I treat 'em\n",
      "We buy our way out of jail, but we can't buy freedom\n",
      "We'a buy a lot of clothes but we don't really need 'em\n",
      "Things we buy to cover up what's inside\n",
      "\n",
      "\n",
      "'Cause they made us hate ourself and love they wealth\n",
      "That's why shorty's hollering, \"Where the ballas' at?\"\n",
      "Drug dealer buy Jordans, crackhead buy crack\n",
      "And a white man get paid off of all a dat\n",
      "\n",
      "\n",
      "But I ain't even gon' act holier than thou\n",
      "'Cause f it, I went to Jacob with 25 thou\n",
      "Before I had a house and I'd do it again\n",
      "'Cause I wanna be on 106 and Park pushing a Benz\n",
      "\n",
      "\n",
      "I wanna act ballerific like it's all terrific\n",
      "I got a couple past due bills, I won't get specific\n",
      "I got a problem with spending before I get it\n",
      "We all self conscious, I'm just the first to admit it\n",
      "\n",
      "\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "Oh, when it all, it all falls down\n",
      "I'm telling you, ohh, it all falls down\n",
      "\n",
      "\n",
      "(I's can't keep workin' like this\n",
      "This grave shift is like a slave ship)\n"
     ]
    }
   ],
   "source": [
    "for line in open('kanye.txt'):   \n",
    "   print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since opening the \"kanye.txt\" file was successful, the operating system returned us a file handle. The file handle is not the actual data contained in the file, but instead it is a “handle” that we can use to read the data. You are given a handle if the requested file exists and you have the proper permissions to read the file.\n",
    "\n",
    "If the file does not exist, open will fail with a traceback and you will not get a handle to access the contents of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'missingfile.text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6484678794cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'missingfile.text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'missingfile.text'"
     ]
    }
   ],
   "source": [
    "f = open('missingfile.text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times, the first line of data file contains headers, i.e., labels for the columns. For example, consider this football data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team,Games,Wins,Losses,Draws,Goals,Goals Allowed,Points\n",
      "Arsenal,38,26,9,3,79,36,87\n",
      "Liverpool,38,24,8,6,67,30,80\n",
      "Manchester United,38,24,5,9,87,45,77\n",
      "Newcastle,38,21,8,9,74,52,71\n",
      "Leeds,38,18,12,8,53,37,66\n",
      "Chelsea,38,17,13,8,66,38,64\n",
      "West_Ham,38,15,8,15,48,57,53\n",
      "Aston_Villa,38,12,14,12,46,47,50\n",
      "Tottenham,38,14,8,16,49,53,50\n",
      "Blackburn,38,12,10,16,55,51,46\n",
      "Southampton,38,12,9,17,46,54,45\n",
      "Middlesbrough,38,12,9,17,35,47,45\n",
      "Fulham,38,10,14,14,36,44,44\n",
      "Charlton,38,10,14,14,38,49,44\n",
      "Everton,38,11,10,17,45,57,43\n",
      "Bolton,38,9,13,16,44,62,40\n",
      "Sunderland,38,10,10,18,29,51,40\n",
      "Ipswich,38,9,9,20,41,64,36\n",
      "Derby,38,8,6,24,33,63,30\n",
      "Leicester,38,5,13,20,30,64,28\n"
     ]
    }
   ],
   "source": [
    "for line in open('football.txt'):   \n",
    "   print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't want to store the header row, we can use \"next\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arsenal,38,26,9,3,79,36,87\n",
      "Liverpool,38,24,8,6,67,30,80\n",
      "Manchester United,38,24,5,9,87,45,77\n",
      "Newcastle,38,21,8,9,74,52,71\n",
      "Leeds,38,18,12,8,53,37,66\n",
      "Chelsea,38,17,13,8,66,38,64\n",
      "West_Ham,38,15,8,15,48,57,53\n",
      "Aston_Villa,38,12,14,12,46,47,50\n",
      "Tottenham,38,14,8,16,49,53,50\n",
      "Blackburn,38,12,10,16,55,51,46\n",
      "Southampton,38,12,9,17,46,54,45\n",
      "Middlesbrough,38,12,9,17,35,47,45\n",
      "Fulham,38,10,14,14,36,44,44\n",
      "Charlton,38,10,14,14,38,49,44\n",
      "Everton,38,11,10,17,45,57,43\n",
      "Bolton,38,9,13,16,44,62,40\n",
      "Sunderland,38,10,10,18,29,51,40\n",
      "Ipswich,38,9,9,20,41,64,36\n",
      "Derby,38,8,6,24,33,63,30\n",
      "Leicester,38,5,13,20,30,64,28\n"
     ]
    }
   ],
   "source": [
    "with open('football.txt') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to store the header for later, you can use readline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arsenal,38,26,9,3,79,36,87\n",
      "Liverpool,38,24,8,6,67,30,80\n",
      "Manchester United,38,24,5,9,87,45,77\n",
      "Newcastle,38,21,8,9,74,52,71\n",
      "Leeds,38,18,12,8,53,37,66\n",
      "Chelsea,38,17,13,8,66,38,64\n",
      "West_Ham,38,15,8,15,48,57,53\n",
      "Aston_Villa,38,12,14,12,46,47,50\n",
      "Tottenham,38,14,8,16,49,53,50\n",
      "Blackburn,38,12,10,16,55,51,46\n",
      "Southampton,38,12,9,17,46,54,45\n",
      "Middlesbrough,38,12,9,17,35,47,45\n",
      "Fulham,38,10,14,14,36,44,44\n",
      "Charlton,38,10,14,14,38,49,44\n",
      "Everton,38,11,10,17,45,57,43\n",
      "Bolton,38,9,13,16,44,62,40\n",
      "Sunderland,38,10,10,18,29,51,40\n",
      "Ipswich,38,9,9,20,41,64,36\n",
      "Derby,38,8,6,24,33,63,30\n",
      "Leicester,38,5,13,20,30,64,28\n",
      "header: Team,Games,Wins,Losses,Draws,Goals,Goals Allowed,Points\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('football.txt') as f:\n",
    "    header = f.readline()\n",
    "    for line in f:\n",
    "        print(line.strip())\n",
    "    print('header:', header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When would storing the header separately be useful? Suppose we want to find the average number of wins of all the teams. If the header string \"Wins\" had been stored in the same list as the numerical wins, then we wouldn't be able to take the average of numbers and the word \"Wins\". First, let us store the team names and their wins in separate lists and print them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team:  Arsenal  \t Wins:  26\n",
      "Team:  Liverpool  \t Wins:  24\n",
      "Team:  Manchester United  \t Wins:  24\n",
      "Team:  Newcastle  \t Wins:  21\n",
      "Team:  Leeds  \t Wins:  18\n",
      "Team:  Chelsea  \t Wins:  17\n",
      "Team:  West_Ham  \t Wins:  15\n",
      "Team:  Aston_Villa  \t Wins:  12\n",
      "Team:  Tottenham  \t Wins:  14\n",
      "Team:  Blackburn  \t Wins:  12\n",
      "Team:  Southampton  \t Wins:  12\n",
      "Team:  Middlesbrough  \t Wins:  12\n",
      "Team:  Fulham  \t Wins:  10\n",
      "Team:  Charlton  \t Wins:  10\n",
      "Team:  Everton  \t Wins:  11\n",
      "Team:  Bolton  \t Wins:  9\n",
      "Team:  Sunderland  \t Wins:  10\n",
      "Team:  Ipswich  \t Wins:  9\n",
      "Team:  Derby  \t Wins:  8\n",
      "Team:  Leicester  \t Wins:  5\n"
     ]
    }
   ],
   "source": [
    "with open('football.txt') as f:\n",
    "    header = f.readline().split(',')\n",
    "    teams = []\n",
    "    wins = []\n",
    "    for line in f:\n",
    "        team_info = line.strip().split(',')\n",
    "        teams.append(team_info[0])\n",
    "        wins.append(int(team_info[2]))\n",
    "        print('Team: ', teams[-1], ' \\t Wins: ', wins[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the code above, we needed to use the .split(',') command to split each line of team info (which was a single string) into a list of the team's info. We also needed to put \"int\" around each win to denote that we wanted it treated as an integer, not a string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the average wins, we can use the following code. Notice that we want to access team_info[2] and header[2] since Wins is the third column in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins 13.95\n"
     ]
    }
   ],
   "source": [
    "with open('football.txt') as f:\n",
    "    header = f.readline().split(',')\n",
    "    wins = []\n",
    "    for line in f:\n",
    "        team_info = line.strip().split(',')\n",
    "        wins.append(int(team_info[2]))\n",
    "\n",
    "print(header[2], sum(wins)/len(wins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Football 1\n",
    "Find the average number of losses. Print out the word \"Losses\" by referencing the correct header item and then the average number of losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert football 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Football 2\n",
    "Read the football file in. Use it to find the team that has the maximum wins. Then print \"Max Wins: 26 by Arsenal\" by referencing:\n",
    "- the header to produce the word \"Wins\"\n",
    "- the max(wins) to produce the number 26\n",
    "- incorporating wins.index(max(wins) to reference the team Arsenal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert football 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Football 3\n",
    "Print the team with the maximum number of losses using the same conditions as above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert football 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to count the number of times \"falls\" appears in the Kanye lyrics. In this case, we will want to break up each sentence into a list of words using the split command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for line in open('kanye.txt'):   \n",
    "    words = line.strip().split()\n",
    "    if 'falls' in words:\n",
    "        count = count +1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to print out what lines in the file \"falls\" is contained on. In that case, we can use the enumerate function. The enumerate function iterates through items in a list and creates an index for them. Let's do an easier example first. Let's say I had a list of colors and I wanted to print the color and its index on a separate line. I would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 red\n",
      "1 blue\n",
      "2 yellow\n",
      "3 blue\n",
      "4 green\n"
     ]
    }
   ],
   "source": [
    "colors = ['red', 'blue', 'yellow', 'blue', 'green']\n",
    "for index, color in enumerate(colors):\n",
    "    print(index, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use enumerate to print the lines that \"falls\" is on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falls is on line 0\n",
      "falls is on line 1\n",
      "falls is on line 4\n",
      "falls is on line 5\n",
      "falls is on line 32\n",
      "falls is on line 33\n",
      "falls is on line 60\n",
      "falls is on line 61\n",
      "falls is on line 88\n",
      "falls is on line 89\n",
      "falls is on line 90\n",
      "falls is on line 91\n",
      "falls is on line 92\n",
      "falls is on line 93\n",
      "falls is on line 94\n",
      "falls is on line 95\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index, line in enumerate(open('kanye.txt')):   \n",
    "    words = line.strip().split()\n",
    "    if 'falls' in words:\n",
    "        print('falls is on line', index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's put everything together. Suppose we want to break up the kanye file into words. We'll make a dictionary of the words and their corresponding frequencies. Then, we'll print out the list of words in decending order of frequency. Let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 it\n",
      "20 all\n",
      "17 down\n",
      "16 i\n",
      "16 falls\n",
      "16 a\n",
      "12 the\n",
      "12 oh,\n",
      "12 and\n",
      "10 i'm\n",
      "9 we\n",
      "9 to\n",
      "9 she\n",
      "8 when\n",
      "8 telling\n",
      "8 buy\n",
      "8 all,\n",
      "7 you,\n",
      "7 that\n",
      "6 you\n",
      "6 with\n",
      "6 so\n",
      "6 of\n",
      "6 like\n",
      "6 'cause\n",
      "5 that's\n",
      "5 her\n",
      "5 can't\n",
      "4 this\n",
      "4 they\n",
      "4 self\n",
      "4 ohh,\n",
      "4 in\n",
      "4 even\n",
      "4 but\n",
      "4 ain't\n",
      "3 up\n",
      "3 she's\n",
      "3 on\n",
      "3 me\n",
      "3 look\n",
      "3 just\n",
      "3 got\n",
      "3 get\n",
      "3 don't\n",
      "3 do\n",
      "3 be\n",
      "2 won't\n",
      "2 why\n",
      "2 wanna\n",
      "2 us\n",
      "2 thou\n",
      "2 things\n",
      "2 then\n",
      "2 some\n",
      "2 seems\n",
      "2 really\n",
      "2 promise,\n",
      "2 people\n",
      "2 our\n",
      "2 off\n",
      "2 no\n",
      "2 money\n",
      "2 man\n",
      "2 it,\n",
      "2 how\n",
      "2 hate\n",
      "2 hair\n",
      "2 had\n",
      "2 for\n",
      "2 f\n",
      "2 conscious\n",
      "2 before\n",
      "2 at\n",
      "2 act\n",
      "2 'em\n",
      "1 years,\n",
      "1 workin'\n",
      "1 without\n",
      "1 will\n",
      "1 white\n",
      "1 what's\n",
      "1 what\n",
      "1 went\n",
      "1 well\n",
      "1 weave\n",
      "1 wealth\n",
      "1 we'a\n",
      "1 way\n",
      "1 watches\n",
      "1 versace\n",
      "1 us,\n",
      "1 ugliest\n",
      "1 trying\n",
      "1 treat\n",
      "1 three\n",
      "1 than\n",
      "1 terrific\n",
      "1 tell\n",
      "1 team\n",
      "1 store\n",
      "1 still\n",
      "1 stay\n",
      "1 spent\n",
      "1 spending\n",
      "1 specific\n",
      "1 sophomore,\n",
      "1 slave\n",
      "1 single\n",
      "1 shorty's\n",
      "1 shirt\n",
      "1 ship)\n",
      "1 shine\n",
      "1 shift\n",
      "1 see\n",
      "1 secure\n",
      "1 screw\n",
      "1 school\n",
      "1 say\n",
      "1 rollies\n",
      "1 road\n",
      "1 rings\n",
      "1 riches\n",
      "1 retail\n",
      "1 pushing\n",
      "1 pronounce\n",
      "1 problem\n",
      "1 prettiest\n",
      "1 pressure\n",
      "1 precious\n",
      "1 police,\n",
      "1 picked\n",
      "1 peer\n",
      "1 past\n",
      "1 pass\n",
      "1 pasha's\n",
      "1 park\n",
      "1 parents\n",
      "1 paper,\n",
      "1 pairs\n",
      "1 paid\n",
      "1 out,\n",
      "1 out\n",
      "1 ourself\n",
      "1 ones\n",
      "1 one\n",
      "1 now,\n",
      "1 now\n",
      "1 nothing,\n",
      "1 new\n",
      "1 need\n",
      "1 named\n",
      "1 my\n",
      "1 man,\n",
      "1 make\n",
      "1 majored\n",
      "1 major\n",
      "1 made\n",
      "1 lowest\n",
      "1 low\n",
      "1 love\n",
      "1 lot\n",
      "1 looked\n",
      "1 long\n",
      "1 living\n",
      "1 like,\n",
      "1 least\n",
      "1 keep\n",
      "1 jordans,\n",
      "1 jail,\n",
      "1 jacob\n",
      "1 it's\n",
      "1 issues\n",
      "1 is\n",
      "1 inside\n",
      "1 insecure\n",
      "1 if\n",
      "1 idea\n",
      "1 i'll\n",
      "1 i'd\n",
      "1 house\n",
      "1 hollering,\n",
      "1 holier\n",
      "1 highest\n",
      "1 here\n",
      "1 has\n",
      "1 grocery\n",
      "1 grave\n",
      "1 gon'\n",
      "1 go\n",
      "1 funny\n",
      "1 freedom\n",
      "1 floss\n",
      "1 first\n",
      "1 few\n",
      "1 female,\n",
      "1 eve\n",
      "1 esteem\n",
      "1 enough\n",
      "1 due\n",
      "1 drug\n",
      "1 drove\n",
      "1 drop\n",
      "1 dream\n",
      "1 done\n",
      "1 doing\n",
      "1 diamond\n",
      "1 degrade\n",
      "1 dealing\n",
      "1 dealer\n",
      "1 daughter\n",
      "1 dat\n",
      "1 daddy\n",
      "1 cut\n",
      "1 crazy\n",
      "1 crackhead\n",
      "1 crack\n",
      "1 cover\n",
      "1 couple\n",
      "1 couldn't\n",
      "1 coop\n",
      "1 conscious,\n",
      "1 concept\n",
      "1 college\n",
      "1 clothes\n",
      "1 clean\n",
      "1 career\n",
      "1 care\n",
      "1 car\n",
      "1 bucks\n",
      "1 brotha\n",
      "1 black\n",
      "1 bills,\n",
      "1 benz,\n",
      "1 benz\n",
      "1 believe\n",
      "1 because\n",
      "1 ballerific\n",
      "1 ballas'\n",
      "1 back\n",
      "1 baby\n",
      "1 at?\"\n",
      "1 american\n",
      "1 always\n",
      "1 alexus\n",
      "1 airs\n",
      "1 again\n",
      "1 afford\n",
      "1 admit\n",
      "1 addicted\n",
      "1 acres\n",
      "1 a'stoop\n",
      "1 400\n",
      "1 40\n",
      "1 25\n",
      "1 106\n",
      "1 (i's\n",
      "1 \"where\n"
     ]
    }
   ],
   "source": [
    "#create the dictionary of words and frequencies:\n",
    "word_dict = {}\n",
    "for line in open('kanye.txt'):\n",
    "    for word in line.split():\n",
    "        word = word.lower()\n",
    "        word_dict[word] = word_dict.get(word,0) + 1\n",
    "\n",
    "#create a list of tuples to sort the words\n",
    "word_list = []\n",
    "for key,val in word_dict.items():\n",
    "    word_list.append((val,key))\n",
    "\n",
    "#print the list in reverse\n",
    "word_list.sort(reverse = True)\n",
    "\n",
    "for key,value in word_list:\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if I had created the list of tuples in the order (key,val) instead of (val,key)? It would have sorted alphabetically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you, 7\n",
      "you 6\n",
      "years, 1\n",
      "workin' 1\n",
      "won't 2\n",
      "without 1\n",
      "with 6\n",
      "will 1\n",
      "why 2\n",
      "white 1\n",
      "when 8\n",
      "what's 1\n",
      "what 1\n",
      "went 1\n",
      "well 1\n",
      "weave 1\n",
      "wealth 1\n",
      "we'a 1\n",
      "we 9\n",
      "way 1\n",
      "watches 1\n",
      "wanna 2\n",
      "versace 1\n",
      "us, 1\n",
      "us 2\n",
      "up 3\n",
      "ugliest 1\n",
      "trying 1\n",
      "treat 1\n",
      "to 9\n",
      "three 1\n",
      "thou 2\n",
      "this 4\n",
      "things 2\n",
      "they 4\n",
      "then 2\n",
      "the 12\n",
      "that's 5\n",
      "that 7\n",
      "than 1\n",
      "terrific 1\n",
      "telling 8\n",
      "tell 1\n",
      "team 1\n",
      "store 1\n",
      "still 1\n",
      "stay 1\n",
      "spent 1\n",
      "spending 1\n",
      "specific 1\n",
      "sophomore, 1\n",
      "some 2\n",
      "so 6\n",
      "slave 1\n",
      "single 1\n",
      "shorty's 1\n",
      "shirt 1\n",
      "ship) 1\n",
      "shine 1\n",
      "shift 1\n",
      "she's 3\n",
      "she 9\n",
      "self 4\n",
      "seems 2\n",
      "see 1\n",
      "secure 1\n",
      "screw 1\n",
      "school 1\n",
      "say 1\n",
      "rollies 1\n",
      "road 1\n",
      "rings 1\n",
      "riches 1\n",
      "retail 1\n",
      "really 2\n",
      "pushing 1\n",
      "pronounce 1\n",
      "promise, 2\n",
      "problem 1\n",
      "prettiest 1\n",
      "pressure 1\n",
      "precious 1\n",
      "police, 1\n",
      "picked 1\n",
      "people 2\n",
      "peer 1\n",
      "past 1\n",
      "pass 1\n",
      "pasha's 1\n",
      "park 1\n",
      "parents 1\n",
      "paper, 1\n",
      "pairs 1\n",
      "paid 1\n",
      "out, 1\n",
      "out 1\n",
      "ourself 1\n",
      "our 2\n",
      "ones 1\n",
      "one 1\n",
      "on 3\n",
      "ohh, 4\n",
      "oh, 12\n",
      "off 2\n",
      "of 6\n",
      "now, 1\n",
      "now 1\n",
      "nothing, 1\n",
      "no 2\n",
      "new 1\n",
      "need 1\n",
      "named 1\n",
      "my 1\n",
      "money 2\n",
      "me 3\n",
      "man, 1\n",
      "man 2\n",
      "make 1\n",
      "majored 1\n",
      "major 1\n",
      "made 1\n",
      "lowest 1\n",
      "low 1\n",
      "love 1\n",
      "lot 1\n",
      "looked 1\n",
      "look 3\n",
      "long 1\n",
      "living 1\n",
      "like, 1\n",
      "like 6\n",
      "least 1\n",
      "keep 1\n",
      "just 3\n",
      "jordans, 1\n",
      "jail, 1\n",
      "jacob 1\n",
      "it, 2\n",
      "it's 1\n",
      "it 30\n",
      "issues 1\n",
      "is 1\n",
      "inside 1\n",
      "insecure 1\n",
      "in 4\n",
      "if 1\n",
      "idea 1\n",
      "i'm 10\n",
      "i'll 1\n",
      "i'd 1\n",
      "i 16\n",
      "how 2\n",
      "house 1\n",
      "hollering, 1\n",
      "holier 1\n",
      "highest 1\n",
      "here 1\n",
      "her 5\n",
      "hate 2\n",
      "has 1\n",
      "hair 2\n",
      "had 2\n",
      "grocery 1\n",
      "grave 1\n",
      "got 3\n",
      "gon' 1\n",
      "go 1\n",
      "get 3\n",
      "funny 1\n",
      "freedom 1\n",
      "for 2\n",
      "floss 1\n",
      "first 1\n",
      "few 1\n",
      "female, 1\n",
      "falls 16\n",
      "f 2\n",
      "even 4\n",
      "eve 1\n",
      "esteem 1\n",
      "enough 1\n",
      "due 1\n",
      "drug 1\n",
      "drove 1\n",
      "drop 1\n",
      "dream 1\n",
      "down 17\n",
      "done 1\n",
      "don't 3\n",
      "doing 1\n",
      "do 3\n",
      "diamond 1\n",
      "degrade 1\n",
      "dealing 1\n",
      "dealer 1\n",
      "daughter 1\n",
      "dat 1\n",
      "daddy 1\n",
      "cut 1\n",
      "crazy 1\n",
      "crackhead 1\n",
      "crack 1\n",
      "cover 1\n",
      "couple 1\n",
      "couldn't 1\n",
      "coop 1\n",
      "conscious, 1\n",
      "conscious 2\n",
      "concept 1\n",
      "college 1\n",
      "clothes 1\n",
      "clean 1\n",
      "career 1\n",
      "care 1\n",
      "car 1\n",
      "can't 5\n",
      "buy 8\n",
      "but 4\n",
      "bucks 1\n",
      "brotha 1\n",
      "black 1\n",
      "bills, 1\n",
      "benz, 1\n",
      "benz 1\n",
      "believe 1\n",
      "before 2\n",
      "because 1\n",
      "be 3\n",
      "ballerific 1\n",
      "ballas' 1\n",
      "back 1\n",
      "baby 1\n",
      "at?\" 1\n",
      "at 2\n",
      "and 12\n",
      "american 1\n",
      "always 1\n",
      "all, 8\n",
      "all 20\n",
      "alexus 1\n",
      "airs 1\n",
      "ain't 4\n",
      "again 1\n",
      "afford 1\n",
      "admit 1\n",
      "addicted 1\n",
      "act 2\n",
      "acres 1\n",
      "a'stoop 1\n",
      "a 16\n",
      "400 1\n",
      "40 1\n",
      "25 1\n",
      "106 1\n",
      "(i's 1\n",
      "'em 2\n",
      "'cause 6\n",
      "\"where 1\n"
     ]
    }
   ],
   "source": [
    "#create a list of tuples to sort the words\n",
    "word_list = []\n",
    "for key,val in word_dict.items():\n",
    "    word_list.append((key,val))\n",
    "\n",
    "#print the list in reverse order\n",
    "word_list.sort(reverse = True)\n",
    "\n",
    "for key,value in word_list:\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we had forgotten .split()? It would have counted the frequency of letters instead of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524  \n",
      "238 e\n",
      "189 a\n",
      "179 t\n",
      "177 l\n",
      "168 o\n",
      "142 s\n",
      "131 n\n",
      "131 h\n",
      "129 i\n",
      "100 \n",
      "\n",
      "81 r\n",
      "75 d\n",
      "71 u\n",
      "63 w\n",
      "55 c\n",
      "53 '\n",
      "52 ,\n",
      "49 f\n",
      "44 y\n",
      "40 m\n",
      "39 g\n",
      "36 p\n",
      "30 I\n",
      "27 b\n",
      "21 k\n",
      "13 v\n",
      "10 T\n",
      "8 O\n",
      "7 W\n",
      "6 S\n",
      "6 C\n",
      "6 A\n",
      "5 j\n",
      "5 B\n",
      "4 0\n",
      "3 z\n",
      "3 J\n",
      "2 P\n",
      "2 M\n",
      "2 E\n",
      "2 4\n",
      "2 \"\n",
      "1 x\n",
      "1 V\n",
      "1 R\n",
      "1 N\n",
      "1 F\n",
      "1 D\n",
      "1 ?\n",
      "1 6\n",
      "1 5\n",
      "1 2\n",
      "1 1\n",
      "1 )\n",
      "1 (\n"
     ]
    }
   ],
   "source": [
    "#create the dictionary of words and frequencies:\n",
    "word_dict = {}\n",
    "for line in open('kanye.txt'):\n",
    "    for word in line:\n",
    "        word_dict[word] = word_dict.get(word,0) + 1\n",
    "\n",
    "#create a list to sort the words\n",
    "word_list = []\n",
    "for key,val in word_dict.items():\n",
    "    word_list.append((val,key))\n",
    "\n",
    "#print the list in reverse order\n",
    "word_list.sort(reverse = True)\n",
    "\n",
    "for key,value in word_list:\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Dance 1\n",
    "Write a program that reads the file dance.txt. It should print the words and counts in decending order of frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert dance code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Dance 2\n",
    "Print out the words and their counts in alphabetically ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert dance again code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Dance 3\n",
    "Write a program that prints out the LYRICS that contain any permutation of the word \"present\", such as \"Present\" or \"presently\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert dance again again code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Dance 4\n",
    "Write a program that prints out the LINE NUMBERS of the lyrics that contain any permutation of the word \"present\", such as \"Present\" or \"presently\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert dance 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - find kanye\n",
    "Suppose we wanted to create a program that doesn't check whether \"kanye\" is a word in the line but checks whether the letters in that line could form the word \"Kanye.\" For example, the line \"But she won't drop out, her parents will look at her funny\" contains the letters k, a, n, y, and e. Write a program that prints the locations of the lines that form the word \"Kanye\" in the kanye.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert kanye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delimiters\n",
    "---\n",
    "<a class=\"anchor\" id=\"delimiters\"></a>\n",
    "\n",
    "Up until now, we have been mostly breaking up sentences by words using .split() with the parenthesis blank. However, we can choose to break up the sentence by any delimiter we want. Consider, for example, the student.txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane Doe, 2000, 101 Main St\n",
      "John Doe, 2001, 123 Oak St\n",
      "Ann Ko, 1999, 57 Tree St\n",
      "Paul Smith, 2000, 60 Spring St\n",
      "Sarah McDonald, 2001, 101 MLK Blvd\n"
     ]
    }
   ],
   "source": [
    "for line in open('students.txt'):\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we want to break up each line by commas. To do this, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jane Doe', ' 2000', ' 101 Main St']\n",
      "['John Doe', ' 2001', ' 123 Oak St']\n",
      "['Ann Ko', ' 1999', ' 57 Tree St']\n",
      "['Paul Smith', ' 2000', ' 60 Spring St']\n",
      "['Sarah McDonald', ' 2001', ' 101 MLK Blvd']\n"
     ]
    }
   ],
   "source": [
    "for line in open('students.txt'):\n",
    "    words = line.strip().split(',')\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then keep separate name, birth year, and address lists by typing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jane Doe', 'John Doe', 'Ann Ko', 'Paul Smith', 'Sarah McDonald']\n",
      "[' 2000', ' 2001', ' 1999', ' 2000', ' 2001']\n",
      "[' 101 Main St', ' 123 Oak St', ' 57 Tree St', ' 60 Spring St', ' 101 MLK Blvd']\n"
     ]
    }
   ],
   "source": [
    "name_list = []\n",
    "birth_year_list = []\n",
    "address_list = []\n",
    "for line in open('students.txt'):\n",
    "    words = line.strip().split(',')\n",
    "    name_list.append(words[0])\n",
    "    birth_year_list.append(words[1])\n",
    "    address_list.append(words[2])\n",
    "print(name_list)\n",
    "print(birth_year_list)\n",
    "print(address_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are a lot of extra spaces on each side of some of the words, so we may want to strip that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jane Doe', 'John Doe', 'Ann Ko', 'Paul Smith', 'Sarah McDonald']\n",
      "['2000', '2001', '1999', '2000', '2001']\n",
      "['101 Main St', '123 Oak St', '57 Tree St', '60 Spring St', '101 MLK Blvd']\n"
     ]
    }
   ],
   "source": [
    "name_list = []\n",
    "birth_year_list = []\n",
    "address_list = []\n",
    "for line in open('students.txt'):\n",
    "    words = line.strip().split(',')\n",
    "    name_list.append(words[0].strip())\n",
    "    birth_year_list.append(words[1].strip())\n",
    "    address_list.append(words[2].strip())\n",
    "print(name_list)\n",
    "print(birth_year_list)\n",
    "print(address_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When searching through a file, we may only care about lines that begin with certain strings. For example, consider this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: janedoe@gmail.com Sat Jan 5 2008\n",
      "To: jackdoe@aol.com\n",
      "Subject: Saturday Party\n",
      "\n",
      "From: annesmith@gmail.com Sun Jan 6 2008\n",
      "To: bobpaul@amazon.com\n",
      "Subject: I’m mad at you\n",
      "\n",
      "From: jackmac@mac.com Mon Jan 7 2008\n",
      "To: catdancy@gmail.com\n",
      "Subject: Not safe for work\n",
      "\n",
      "From: paullauren@gmail.com Tues Jan 9 2008\n",
      "To: mikejoy@aol.com\n",
      "Subject: For sale\n"
     ]
    }
   ],
   "source": [
    "for line in open('mailbox.txt'):\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we only wanted to save the email addresses of the people who sent the emails (in the From: lines). We could use the command .startswith():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: janedoe@gmail.com Sat Jan 5 2008\n",
      "\n",
      "From: annesmith@gmail.com Sun Jan 6 2008\n",
      "\n",
      "From: jackmac@mac.com Mon Jan 7 2008\n",
      "\n",
      "From: paullauren@gmail.com Tues Jan 9 2008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we could save those emails by breaking up each line into words and saving the second word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['janedoe@gmail.com', 'annesmith@gmail.com', 'jackmac@mac.com', 'paullauren@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "names=[]\n",
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        words = line.split()\n",
    "        names.append(words[1])\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or more succinctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['janedoe@gmail.com', 'annesmith@gmail.com', 'jackmac@mac.com', 'paullauren@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "names=[]\n",
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        names.append(line.split()[1])\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you only wanted to save the username part of the email addresses to the right of the @ sign. You could use a delimiter again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "janedoe\n",
      "annesmith\n",
      "jackmac\n",
      "paullauren\n"
     ]
    }
   ],
   "source": [
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        words = line.split()[1].split('@')\n",
    "        print(words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or more succinctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "janedoe\n",
      "annesmith\n",
      "jackmac\n",
      "paullauren\n"
     ]
    }
   ],
   "source": [
    "names=[]\n",
    "for line in open('mailbox.txt'):\n",
    "    if line.startswith('From:'):\n",
    "        print(line.split()[1].split('@')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - sports 1\n",
    "Open the file sports.txt. Break up each line by the delimiter \"-\". Then print a list of what each student plays in the spring. For example, each line should say something like \"Brenda plays track in the spring.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert sports code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - sports 2\n",
    "Print a count of how many students are enrolled in each sport. For example, your output will contain something like \"2 students play soccer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert sports again code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Football 5\n",
    "Break up the football.txt data using comma delimiters. Store the team names in a list. Make sure to skip the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert football"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Football 6\n",
    "Store the football.txt data as a list of lists for the different team data. Then, find the team that has the minimum absolute value difference between their goals and goals allowed. (Hint: the answer should be Aston Villa.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert football 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Files\n",
    "---\n",
    "<a class=\"anchor\" id=\"csv\"></a>\n",
    "The so-called CSV (Comma Separated Values) format is the most common import and export format for spreadsheets and databases. For example, you can always store an Excel or Google sheet in CSV format. We can read them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', ' degree', ' title', ' email']\n",
      "['Scarlett L. Bellamy', ' Sc.D.', 'Associate Professor of Biostatistics', 'bellamys@mail.med.upenn.edu']\n",
      "['Warren B. Bilker', 'Ph.D.', 'Professor of Biostatistics', 'warren@upenn.edu']\n",
      "['Matthew W Bryan', ' PhD', 'Assistant Professor of Biostatistics', 'bryanma@upenn.edu']\n",
      "['Jinbo Chen', ' Ph.D.', 'Associate Professor of Biostatistics', 'jinboche@upenn.edu']\n",
      "['Susan S Ellenberg', ' Ph.D.', 'Professor of Biostatistics', 'sellenbe@upenn.edu']\n",
      "['Jonas H. Ellenberg', ' Ph.D.', 'Professor of Biostatistics', 'jellenbe@mail.med.upenn.edu']\n",
      "['Rui Feng', ' Ph.D', 'Assistant Professor of Biostatistics', 'ruifeng@upenn.edu']\n",
      "['Benjamin C. French', ' PhD', 'Associate Professor of Biostatistics', 'bcfrench@mail.med.upenn.edu']\n",
      "['Phyllis A. Gimotty', ' Ph.D', 'Professor of Biostatistics', 'pgimotty@upenn.edu']\n",
      "['Wensheng Guo', ' Ph.D', 'Professor of Biostatistics', 'wguo@mail.med.upenn.edu']\n",
      "['Yenchih Hsu', ' Ph.D.', 'Assistant Professor of Biostatistics', 'hsu9@mail.med.upenn.edu']\n",
      "['Rebecca A Hubbard', ' PhD', 'Associate Professor of Biostatistics', 'rhubb@mail.med.upenn.edu']\n",
      "['Wei-Ting Hwang', ' Ph.D.', 'Associate Professor of Biostatistics', 'whwang@mail.med.upenn.edu']\n",
      "['Marshall M. Joffe', ' MD MPH Ph.D', 'Professor of Biostatistics', 'mjoffe@mail.med.upenn.edu']\n",
      "['J. Richard Landis', ' B.S.Ed. M.S. Ph.D.', 'Professor of Biostatistics', 'jrlandis@mail.med.upenn.edu']\n",
      "['Yimei Li', ' Ph.D.', 'Assistant Professor of Biostatistics', 'liy3@email.chop.edu']\n",
      "['Mingyao Li', ' Ph.D.', 'Associate Professor of Biostatistics', 'mingyao@mail.med.upenn.edu']\n",
      "['Hongzhe Li', ' Ph.D', 'Professor of Biostatistics', 'hongzhe@upenn.edu']\n",
      "['A. Russell Localio', ' JD MA MPH MS PhD', 'Associate Professor of Biostatistics', 'rlocalio@upenn.edu']\n",
      "['Nandita Mitra', ' Ph.D.', 'Associate Professor of Biostatistics', 'nanditam@mail.med.upenn.edu']\n",
      "['Knashawn H. Morales', ' Sc.D.', 'Associate Professor of Biostatistics', 'knashawn@mail.med.upenn.edu']\n",
      "['Kathleen Joy Propert', ' Sc.D.', 'Professor of Biostatistics', 'propert@mail.med.upenn.edu']\n",
      "['Mary E. Putt', ' PhD ScD', 'Professor of Biostatistics', 'mputt@mail.med.upenn.edu']\n",
      "['Sarah Jane Ratcliffe', ' Ph.D.', 'Associate Professor of Biostatistics', 'sratclif@upenn.edu']\n",
      "['Michelle Elana Ross', ' PhD', 'Assistant Professor is Biostatistics', 'michross@upenn.edu']\n",
      "['Jason A. Roy', ' Ph.D.', 'Associate Professor of Biostatistics', 'jaroy@mail.med.upenn.edu']\n",
      "['Mary D. Sammel', ' Sc.D.', 'Professor of Biostatistics', 'msammel@cceb.med.upenn.edu']\n",
      "['Pamela Ann Shaw', ' PhD', 'Assistant Professor of Biostatistics', 'shawp@upenn.edu']\n",
      "['Russell Takeshi Shinohara', '0', 'Assistant Professor of Biostatistics', 'rshi@mail.med.upenn.edu']\n",
      "['Haochang Shou', ' Ph.D.', 'Assistant Professor of Biostatistics', 'hshou@mail.med.upenn.edu']\n",
      "['Justine Shults', ' Ph.D.', 'Professor of Biostatistics', 'jshults@mail.med.upenn.edu']\n",
      "['Alisa Jane Stephens', ' Ph.D.', 'Assistant Professor of Biostatistics', 'alisaste@mail.med.upenn.edu']\n",
      "['Andrea Beth Troxel', ' ScD', 'Professor of Biostatistics', 'atroxel@mail.med.upenn.edu']\n",
      "['Rui Xiao', ' PhD', 'Assistant Professor of Biostatistics', 'rxiao@mail.med.upenn.edu']\n",
      "['Sharon Xiangwen Xie', ' Ph.D.', 'Associate Professor of Biostatistics', 'sxie@mail.med.upenn.edu']\n",
      "['Dawei Xie', ' PhD', 'Assistant Professor of Biostatistics', 'dxie@upenn.edu']\n",
      "['Wei (Peter) Yang', ' Ph.D.', 'Assistant Professor of Biostatistics', 'weiyang@mail.med.upenn.edu']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "degree=[]\n",
    "\n",
    "with open('faculty.csv') as csvfile:\n",
    "    data = csv.reader(csvfile, delimiter=',')\n",
    "    for row in data:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first row is a header. If you wanted to skip it, you could type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Scarlett L. Bellamy', ' Sc.D.', 'Associate Professor of Biostatistics', 'bellamys@mail.med.upenn.edu']\n",
      "['Warren B. Bilker', 'Ph.D.', 'Professor of Biostatistics', 'warren@upenn.edu']\n",
      "['Matthew W Bryan', ' PhD', 'Assistant Professor of Biostatistics', 'bryanma@upenn.edu']\n",
      "['Jinbo Chen', ' Ph.D.', 'Associate Professor of Biostatistics', 'jinboche@upenn.edu']\n",
      "['Susan S Ellenberg', ' Ph.D.', 'Professor of Biostatistics', 'sellenbe@upenn.edu']\n",
      "['Jonas H. Ellenberg', ' Ph.D.', 'Professor of Biostatistics', 'jellenbe@mail.med.upenn.edu']\n",
      "['Rui Feng', ' Ph.D', 'Assistant Professor of Biostatistics', 'ruifeng@upenn.edu']\n",
      "['Benjamin C. French', ' PhD', 'Associate Professor of Biostatistics', 'bcfrench@mail.med.upenn.edu']\n",
      "['Phyllis A. Gimotty', ' Ph.D', 'Professor of Biostatistics', 'pgimotty@upenn.edu']\n",
      "['Wensheng Guo', ' Ph.D', 'Professor of Biostatistics', 'wguo@mail.med.upenn.edu']\n",
      "['Yenchih Hsu', ' Ph.D.', 'Assistant Professor of Biostatistics', 'hsu9@mail.med.upenn.edu']\n",
      "['Rebecca A Hubbard', ' PhD', 'Associate Professor of Biostatistics', 'rhubb@mail.med.upenn.edu']\n",
      "['Wei-Ting Hwang', ' Ph.D.', 'Associate Professor of Biostatistics', 'whwang@mail.med.upenn.edu']\n",
      "['Marshall M. Joffe', ' MD MPH Ph.D', 'Professor of Biostatistics', 'mjoffe@mail.med.upenn.edu']\n",
      "['J. Richard Landis', ' B.S.Ed. M.S. Ph.D.', 'Professor of Biostatistics', 'jrlandis@mail.med.upenn.edu']\n",
      "['Yimei Li', ' Ph.D.', 'Assistant Professor of Biostatistics', 'liy3@email.chop.edu']\n",
      "['Mingyao Li', ' Ph.D.', 'Associate Professor of Biostatistics', 'mingyao@mail.med.upenn.edu']\n",
      "['Hongzhe Li', ' Ph.D', 'Professor of Biostatistics', 'hongzhe@upenn.edu']\n",
      "['A. Russell Localio', ' JD MA MPH MS PhD', 'Associate Professor of Biostatistics', 'rlocalio@upenn.edu']\n",
      "['Nandita Mitra', ' Ph.D.', 'Associate Professor of Biostatistics', 'nanditam@mail.med.upenn.edu']\n",
      "['Knashawn H. Morales', ' Sc.D.', 'Associate Professor of Biostatistics', 'knashawn@mail.med.upenn.edu']\n",
      "['Kathleen Joy Propert', ' Sc.D.', 'Professor of Biostatistics', 'propert@mail.med.upenn.edu']\n",
      "['Mary E. Putt', ' PhD ScD', 'Professor of Biostatistics', 'mputt@mail.med.upenn.edu']\n",
      "['Sarah Jane Ratcliffe', ' Ph.D.', 'Associate Professor of Biostatistics', 'sratclif@upenn.edu']\n",
      "['Michelle Elana Ross', ' PhD', 'Assistant Professor is Biostatistics', 'michross@upenn.edu']\n",
      "['Jason A. Roy', ' Ph.D.', 'Associate Professor of Biostatistics', 'jaroy@mail.med.upenn.edu']\n",
      "['Mary D. Sammel', ' Sc.D.', 'Professor of Biostatistics', 'msammel@cceb.med.upenn.edu']\n",
      "['Pamela Ann Shaw', ' PhD', 'Assistant Professor of Biostatistics', 'shawp@upenn.edu']\n",
      "['Russell Takeshi Shinohara', '0', 'Assistant Professor of Biostatistics', 'rshi@mail.med.upenn.edu']\n",
      "['Haochang Shou', ' Ph.D.', 'Assistant Professor of Biostatistics', 'hshou@mail.med.upenn.edu']\n",
      "['Justine Shults', ' Ph.D.', 'Professor of Biostatistics', 'jshults@mail.med.upenn.edu']\n",
      "['Alisa Jane Stephens', ' Ph.D.', 'Assistant Professor of Biostatistics', 'alisaste@mail.med.upenn.edu']\n",
      "['Andrea Beth Troxel', ' ScD', 'Professor of Biostatistics', 'atroxel@mail.med.upenn.edu']\n",
      "['Rui Xiao', ' PhD', 'Assistant Professor of Biostatistics', 'rxiao@mail.med.upenn.edu']\n",
      "['Sharon Xiangwen Xie', ' Ph.D.', 'Associate Professor of Biostatistics', 'sxie@mail.med.upenn.edu']\n",
      "['Dawei Xie', ' PhD', 'Assistant Professor of Biostatistics', 'dxie@upenn.edu']\n",
      "['Wei (Peter) Yang', ' Ph.D.', 'Assistant Professor of Biostatistics', 'weiyang@mail.med.upenn.edu']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "degree=[]\n",
    "\n",
    "with open('faculty.csv') as csvfile:\n",
    "    data = csv.reader(csvfile, delimiter=',')\n",
    "    next(data, None)\n",
    "    for row in data:\n",
    "        print(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to write to a csv file, we could type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emails = ['janedoe@gmail.com', 'jackdoe@amazon.com', 'sallysmith@aol.com']        \n",
    "with open('emails.csv', 'w', newline='') as csvfile:\n",
    "    myfile = csv.writer(csvfile)\n",
    "    myfile.writerow(['list_of_emails'])\n",
    "    for email in emails:\n",
    "            myfile.writerow([email])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we needed to put each string that we wanted to write to the csv file inside brackets. Otherwise, it would create a space between each letter in the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Degrees\n",
    "\n",
    "Write a program that reads in faculty.csv and creates a dictionary of each degree (standardized to not include periods) and the count of each title. \n",
    "\n",
    "Your program should print: {'0': 1, 'PhD': 31, 'MPH': 2, 'ScD': 6, 'MS': 2, 'BSEd': 1, 'MA': 1, 'MD': 1, 'JD': 1}\n",
    "\n",
    "Hint: One way to get rid of periods is to use .replace('.' , '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Title\n",
    "Write a program that reads in faculty.csv and creates a dictionary of each title and count. \n",
    "\n",
    "Your program should print: {'Professor of Biostatistics': 13, 'Assistant Professor of Biostatistics': 12, 'Associate Professor of Biostatistics': 12}\n",
    "\n",
    "Note: You'll need to account for a typo in the csv file by using \"replace\". Note: this is called data cleaning and is a HUUUUUUGE (not necessarily fun) part of data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - email\n",
    "Write a program that reads in faculty.csv and creates a unique list of the domain names (after the \"@\" symbol in the email address). Your program should print: {'cceb.med.upenn.edu', 'email.chop.edu', 'upenn.edu', 'mail.med.upenn.edu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - last name\n",
    "Write a program that reads in faculty.csv and creates a dictionary such that they key is the last name and the value is a list of the degree, title, and email. Be careful to account for duplicate last names. For example:\n",
    "\n",
    "'Bellamy': [[' Sc.D.', 'Associate Professor of Biostatistics', 'bellamys@mail.med.upenn.edu']]\n",
    "\n",
    "and\n",
    "\n",
    "'Li': [[' Ph.D.', 'Assistant Professor of Biostatistics', 'liy3@email.chop.edu'], [' Ph.D.', 'Associate Professor of Biostatistics', 'mingyao@mail.med.upenn.edu'], [' Ph.D', 'Professor of Biostatistics', 'hongzhe@upenn.edu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert last name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - tuple\n",
    "Write a program that reads in faculty.csv and creates a dictionary such that the key is a tuple of the name and the value is the list of the degree, title, and email. You can assume each tuple name is unique. For example:\n",
    "\n",
    "('Benjamin', 'C.', 'French'): [' PhD',\n",
    "  'Associate Professor of Biostatistics',\n",
    "  'bcfrench@mail.med.upenn.edu']\n",
    "  \n",
    "  \n",
    " ('Dawei', 'Xie'): [' PhD',\n",
    "  'Assistant Professor of Biostatistics',\n",
    "  'dxie@upenn.edu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - write names\n",
    "\n",
    "Write a program that reads in faculty.csv and writes the names of the professors to a list called names.csv. You should include a header in the file such that the first line says \"Professor Names\".\n",
    "\n",
    "Note: to check that you did it correctly, you can always read your \"names.csv\" file back in to view it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert write names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Output\n",
    "---\n",
    "<a class=\"anchor\" id=\"output\"></a>\n",
    "\n",
    "To write a file, you have to open it with mode 'w' as a second parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='output.txt' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "fout = open('output.txt', 'w')\n",
    "print(fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file already exists, opening it in write mode clears out the old data and starts fresh, so be careful! If the file doesn’t exist, a new one is created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The write method of the file handle object puts data into the file. The file object keeps track of where it is, so if you call write again, it adds the new data to the end.\n",
    "\n",
    "When you are done writing, you have to close the file to make sure that the last bit of data is physically written to the disk so it will not be lost if the power goes off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fout = open('output.txt', 'w')\n",
    "\n",
    "line1 = \"Oh, when it all, it all falls down,\\n\"\n",
    "fout.write(line1)\n",
    "\n",
    "line2 = \"I'm telling you, oh, it all falls down,\\n\"\n",
    "fout.write(line2)\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the above code that we had to add new line characters. The print statement automatically appends a newline, but the write method does not add the newline automatically. If you want each sentence to be on a different line, you'll need to add a \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that we actually wrote to that file, we can open it and read it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, when it all, it all falls down,\n",
      "\n",
      "I'm telling you, oh, it all falls down,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('output.txt'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to insure that the file is properly closed is to use the \"with\" keyword. The advantage is that the file is properly closed after its suite finishes - you don't need to remember to put \"f.close()\" at the end of the line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output.txt', 'w') as fout:\n",
    "\n",
    "    line1 = \"Oh, when it all, it all falls down,\\n\"\n",
    "    fout.write(line1)\n",
    "\n",
    "    line2 = \"I'm telling you, oh, it all falls down,\\n\"\n",
    "    fout.write(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to clear that file and rewrite the numbers between 1 and 10, we can type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fout = open('output.txt', 'w')\n",
    "for i in range(1,11):\n",
    "    fout.write('Number:'+str(i)+'\\n')\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, let's check our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number:1\n",
      "\n",
      "Number:2\n",
      "\n",
      "Number:3\n",
      "\n",
      "Number:4\n",
      "\n",
      "Number:5\n",
      "\n",
      "Number:6\n",
      "\n",
      "Number:7\n",
      "\n",
      "Number:8\n",
      "\n",
      "Number:9\n",
      "\n",
      "Number:10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('output.txt'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we needed to use plus signs instead of commas. Write does not accept commas between words like print does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() takes exactly one argument (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-8b0a56fa5e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() takes exactly one argument (3 given)"
     ]
    }
   ],
   "source": [
    "fout = open('output.txt', 'w')\n",
    "for i in range(1,11):\n",
    "    fout.write('Number:',str(i),'\\n')\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to continue adding the numbers 11 through 20 to the same text file. If we write to the file again, denoted by a \"w\", we'll end up clearing out the numbers 1-10 and replacing them with 11-20. If we want to append to the file created already, denoted by \"a\", then we can create all numbers 1-20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fout = open('output.txt', 'a')\n",
    "for i in range(11,21):\n",
    "    fout.write('Number:'+str(i)+'\\n')\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number:1\n",
      "\n",
      "Number:2\n",
      "\n",
      "Number:3\n",
      "\n",
      "Number:4\n",
      "\n",
      "Number:5\n",
      "\n",
      "Number:6\n",
      "\n",
      "Number:7\n",
      "\n",
      "Number:8\n",
      "\n",
      "Number:9\n",
      "\n",
      "Number:10\n",
      "\n",
      "Number:11\n",
      "\n",
      "Number:12\n",
      "\n",
      "Number:13\n",
      "\n",
      "Number:14\n",
      "\n",
      "Number:15\n",
      "\n",
      "Number:16\n",
      "\n",
      "Number:17\n",
      "\n",
      "Number:18\n",
      "\n",
      "Number:19\n",
      "\n",
      "Number:20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('output.txt'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - multiples\n",
    "Write a program that stores the first 100 multiples of 7, each on a different line, in a file called 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - kanye\n",
    "Write a program that calculates Kanye's most used words in kanye.txt and prints them to a file, in decending order of frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert kanye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - calendar app\n",
    "Write a program that takes in a date in the form \"MM-DD-YY' and a reminder for that day. For example, a user might input \"09-27-17\" and \"Get Lauren a Birthday Present.\" The program should add this information to the file calendar.txt each time the user calls the program. One caveat: if the user enters a date that is already in the file, then that reminder should be inserted in the right spot, rather than at the end of the file. For example, two reminders for the date \"09-27-17\" should be next to each other. \n",
    "\n",
    "Hint: to do this, google \"Insert line at middle of file with Python\" and read the StackOverflow article. \n",
    "\n",
    "You don't need to worry about putting all of the dates in chronological order just yet. We'll do that in another program later when we get to the datetime module. You can google it now if you are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert calendar app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files in Other Locations\n",
    "---\n",
    "<a class=\"anchor\" id=\"locations\"></a>\n",
    "\n",
    "We have been reading files that are located in the directory of this program. If we needed to search somewhere else for the file, we would need to add a bit more to our file path name. \n",
    "\n",
    "On a Mac, if your username was janedoe and you wanted to print from a \"hello.txt\" file located in your Documents folder, you would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in open('/Users/janedoe/Documents/hello.txt'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a PC, you would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in open('C:/Users/janedoe/Documents/hello.txt'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, neither of these will work, since we don't have a file called \"hello.txt\" located there.\n",
    "\n",
    "There's an easier way to reference the file path name rather than typing it all in, and that involves using the OS package.\n",
    "\n",
    "To print the working directory of this assignment (meaning the folder that this file lies in), we can type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shareshianl/Documents/CS/Unit 7 - File Input Output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to ask the user for the name of a file that they want to create within this working directory, and then print a full file path for where this file is located. We could type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What file name do you want to create? turtles.txt\n",
      "/Users/shareshianl/Documents/CS/Unit 7 - File Input Output/turtles.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_name = input('What file name do you want to create? ')\n",
    "file_path = os.getcwd()+'/'+file_name\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to ask the user for a file. If that file already exists, we want to add the user's words to the file. If the file doesn't exist, we want to create a new one. We would need to import the os package if using a Mac:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What file do you want to add words to? journal.txt\n",
      "What do you want to say? This is another journal entry!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = input('What file do you want to add words to? ')\n",
    "say = input('What do you want to say? ')\n",
    "data = []\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(say+'\\n')    \n",
    "else:\n",
    "    f = open(filename, 'w')\n",
    "    f.write(say+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you wanted to find the full path name of the file? You would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What file are you looking for? journal.txt\n",
      "/Users/shareshianl/Documents/CS/Unit 7 - File Input Output/journal.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = input('What file are you looking for? ')\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    print(os.path.abspath(filename))\n",
    "else:\n",
    "    print('That file does not exist.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Fave Song\n",
    "\n",
    "Use the OS package to create a file path that includes your current working directory and the name of your favorite song in the file name, such as \"Ignition.txt\".\n",
    "\n",
    "Write a few lyrics to the song on different lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert fave song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Fave Song 2\n",
    "\n",
    "Let's crowd source this lyric builder. Ask the user for what song they want to add lyrics to. If they say something other than \"Ignition\", then create a new file for that song and have the user write lyrics to that song. If they say \"Ignition\", then have the user append more lyrics to the Ignition.txt file without overwriting the lyrics you've already saved there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert Fave Song 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
